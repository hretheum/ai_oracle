# üîç FAZA 1: Pipeline zbierania danych

[‚Üê Powr√≥t do g≈Ç√≥wnego planu](./ROADMAP_MASTER.md) | [‚Üê Poprzednia: Faza 0](./phase_0_foundation.md)

## PrzeglƒÖd
Budowa pipeline'u do zbierania artyku≈Ç√≥w i wczesnych sygna≈Ç√≥w. Fokus na automatyzacji i skalowalno≈õci.

## Czas trwania i zasoby
- **Ca≈Çkowity czas**: 1 tydzie≈Ñ (40h pracy)
- **Wymagane umiejƒôtno≈õci**: Integracja API, podstawy Make.com
- **Bud≈ºet**: $0-100 (Twitter API opcjonalne)

## Kryteria sukcesu
- [ ] 1000+ artyku≈Ç√≥w zebranych z metadanymi
- [ ] Wczesne sygna≈Çy dla 100+ artyku≈Ç√≥w o wysokim wyniku
- [ ] Dane historyczne gotowe do trenowania ML
- [ ] Automatyczne codzienne zbieranie dzia≈Ça

---

## 1.1 Blok crawlera ArXiv [8h]

### Wymagania wstƒôpne
- Konto Make.com aktywne
- Tabela Papers w Airtable gotowa

### Zadania
- [ ] **1.1.1** Utw√≥rz scenariusz crawlera ArXiv (30 min)
  - Nowy scenariusz: "Oracle - ArXiv Daily Crawler"
  - Wyzwalacz harmonogramu: Codziennie 6:00 UTC
  - ‚úì **Walidacja**: Wyzwalacz zaplanowany

- [ ] **1.1.2** Skonfiguruj modu≈Ç ArXiv API (45 min)
  ```
  Modu≈Ç HTTP Request:
  - URL: http://export.arxiv.org/api/query
  - Metoda: GET
  - Query String:
    * search_query: cat:cs.AI OR cat:cs.LG OR cat:cs.CL
    * start: 0
    * max_results: 50
    * sortBy: submittedDate
    * sortOrder: descending
  ```
  - ‚úì **Walidacja**: Zwraca XML z artyku≈Çami

- [ ] **1.1.3** Parsuj odpowied≈∫ XML (1h)
  - Dodaj modu≈Ç XML Parser
  - Mapuj do struktury JSON
  - Wyodrƒôbnij wszystkie wƒôz≈Çy entry
  - ‚úì **Walidacja**: Widzisz tablicƒô artyku≈Ç√≥w

- [ ] **1.1.4** Konfiguracja iteratora (30 min)
  - Dodaj modu≈Ç Iterator
  - Wej≈õcie: sparsowana tablica entries
  - ‚úì **Walidacja**: Przetwarza ka≈ºdy artyku≈Ç

- [ ] **1.1.5** Mapowanie danych (1h)
  ```
  Dla ka≈ºdego artyku≈Çu, wyodrƒôbnij:
  - title: {{entry.title}}
  - arxiv_id: {{split(entry.id; "/")[last]}}
  - authors: {{join(map(entry.author; "name"); ", ")}}
  - abstract: {{entry.summary}}
  - pdf_url: {{first(map(filter(entry.link; href; contains(href; "pdf")); "href"))}}
  - submitted_date: {{parseDate(entry.published; "YYYY-MM-DD")}}
  ```
  - ‚úì **Walidacja**: Wszystkie pola zmapowane poprawnie

- [ ] **1.1.6** Zapisz do Airtable (45 min)
  - Dodaj modu≈Ç Airtable "Create Record"
  - Mapuj wszystkie pola
  - Ustaw obs≈Çugƒô b≈Çƒôd√≥w
  - ‚úì **Walidacja**: Testowy artyku≈Ç zapisany

- [ ] **1.1.7** Sprawdzanie duplikat√≥w (30 min)
  - Przed zapisem, szukaj istniejƒÖcego arxiv_id
  - Pomi≈Ñ je≈õli istnieje
  - ‚úì **Walidacja**: Brak tworzonych duplikat√≥w

### Brama jako≈õci
Uruchom pe≈Çny scenariusz, zebrano 50+ artyku≈Ç√≥w? ‚Üí ‚úÖ Kontynuuj

---

## 1.2 Kolektor metryk autor√≥w [6h]

### Zadania
- [ ] **1.2.1** Dodaj modu≈Ç Semantic Scholar (1h)
  - Po Iterator, dodaj Router
  - Pierwsza trasa: Wyszukiwanie autora
  - HTTP Request do SS API
  - ‚úì **Walidacja**: Zwraca dane autora

- [ ] **1.2.2** Wyodrƒôbnij pierwszego autora (30 min)
  ```javascript
  // Pobierz imiƒô pierwszego autora
  const authors = {{split(5.authors; ",")}}
  const firstAuthor = {{trim(first(authors))}}
  ```
  - ‚úì **Walidacja**: Czyste imiƒô autora

- [ ] **1.2.3** Szukaj autora (45 min)
  ```
  URL: https://api.semanticscholar.org/graph/v1/author/search
  Query: {{firstAuthor}}
  Fields: authorId,name,hIndex,citationCount
  ```
  - ‚úì **Walidacja**: Zwraca dopasowania autora

- [ ] **1.2.4** Pobierz h-index (30 min)
  - Parsuj odpowied≈∫
  - Znajd≈∫ najlepsze dopasowanie po podobie≈Ñstwie nazwy
  - Wyodrƒôbnij h-index
  - ‚úì **Walidacja**: Numeryczny h-index lub 0

- [ ] **1.2.5** Sprawd≈∫ instytucjƒô (45 min)
  ```javascript
  // Lista top instytucji
  const topUnis = ["MIT", "Stanford", "CMU", "Berkeley", "Google", "DeepMind", "OpenAI"]
  const hasTop = topUnis.some(uni => 
    {{5.authors}}.toLowerCase().includes(uni.toLowerCase())
  )
  ```
  - ‚úì **Walidacja**: Boolean true/false

### Brama jako≈õci
Metryki autor√≥w zebrane dla 20+ artyku≈Ç√≥w? ‚Üí ‚úÖ Kontynuuj

---

## 1.3 Kolektor sygna≈Ç√≥w spo≈Çeczno≈õciowych [8h]

### Zadania
- [ ] **1.3.1** Licznik wzmianek na Twitterze (2h) `OPCJONALNE`
  - Je≈õli brak Twitter API, przejd≈∫ do 1.3.4
  - Dodaj modu≈Ç wyszukiwania Twitter
  - Szukaj: arxiv_id LUB tytu≈Ç artyku≈Çu
  - Policz wzmianki w 24h
  - ‚úì **Walidacja**: Liczba ‚â• 0

- [ ] **1.3.2** Wyszukiwarka implementacji GitHub (2h)
  ```
  GitHub Search API:
  - Query: "{arxiv_id}" OR "{pierwsze 30 znak√≥w tytu≈Çu}"
  - Sort: stars
  - Created: >submitted_date
  ```
  - ‚úì **Walidacja**: Lista repozytori√≥w lub pusta

- [ ] **1.3.3** Oblicz sygna≈Ç GitHub (1h)
  ```javascript
  const hasImplementation = {{length(12.items) > 0}}
  const totalStars = {{sum(map(12.items; "stargazers_count"))}}
  const repoCount = {{length(12.items)}}
  ```
  - ‚úì **Walidacja**: Warto≈õci numeryczne

- [ ] **1.3.4** Alternatywne sygna≈Çy (1h)
  - Je≈õli brak Twittera, u≈ºyj:
    * Gwiazdki GitHub jako proxy
    * Reputacja autora
    * Presti≈º instytucji
  - ‚úì **Walidacja**: Zebrano jaki≈õ sygna≈Ç

### Brama jako≈õci
Sygna≈Çy spo≈Çeczno≈õciowe dla 50+ artyku≈Ç√≥w? ‚Üí ‚úÖ Kontynuuj

---

## 1.4 Kalkulator Early Signals Score [4h]

### Zadania
- [ ] **1.4.1** Utw√≥rz funkcjƒô punktacji (1h)
  ```javascript
  // W module Tools Make.com
  let score = 0;
  
  // Autor (40 pkt max)
  score += Math.min({{authorHIndex}} / 2, 15);
  score += {{hasTopInstitution}} ? 10 : 0;
  
  // Spo≈Çeczno≈õciowe (30 pkt max)  
  score += Math.min({{twitterMentions}} / 10, 10);
  score += {{hasGitHub}} ? 5 : 0;
  score += Math.min({{githubStars}} / 10, 5);
  
  // Tre≈õƒá (20 pkt max)
  const hasCode = {{contains(lower(abstract); "github.com")}} ? 5 : 0;
  const hasSOTA = {{contains(lower(abstract); "state-of-the-art")}} ? 7 : 0;
  score += hasCode + hasSOTA;
  
  return Math.min(score, 100);
  ```
  - ‚úì **Walidacja**: Zwraca 0-100

- [ ] **1.4.2** Aktualizuj rekord Airtable (30 min)
  - Dodaj wynik do rekordu artyku≈Çu
  - Ustaw flagƒô needs_prediction
  - ‚úì **Walidacja**: Wynik widoczny w Airtable

### Brama jako≈õci
100+ artyku≈Ç√≥w ocenionych? Zidentyfikowano artyku≈Çy o wysokim wyniku? ‚Üí ‚úÖ Kontynuuj

---

## 1.5 Zbieranie danych historycznych [8h]

### Cel
Potrzebujemy artyku≈Ç√≥w z lat 2020-2022 ze znanymi cytowaniami do trenowania ML

### Zadania
- [ ] **1.5.1** Utw√≥rz crawler historyczny (1h)
  - Zduplikuj dzienny crawler
  - Nazwa: "Oracle - Historical Backfill"
  - Wyzwalacz rƒôczny
  - ‚úì **Walidacja**: Mo≈ºna uruchomiƒá rƒôcznie

- [ ] **1.5.2** Zmodyfikuj zakres dat (30 min)
  ```
  Dla ka≈ºdego miesiƒÖca 2020-2022:
  - search_query: cat:cs.AI AND submittedDate:[20200101 TO 20200131]
  - max_results: 500
  ```
  - ‚úì **Walidacja**: Zwraca stare artyku≈Çy

- [ ] **1.5.3** Dodaj wyszukiwanie cytowa≈Ñ (2h)
  - Po podstawowych informacjach, wywo≈Çaj Semantic Scholar
  - Pobierz aktualnƒÖ liczbƒô cytowa≈Ñ
  - Zapisz jako "citations_current"
  - ‚úì **Walidacja**: Liczby cytowa≈Ñ dodane

- [ ] **1.5.4** Uruchom miesiƒôczne partie (4h)
  - Przetwarzaj jeden miesiƒÖc na raz
  - Monitoruj limity
  - Cel og√≥lny: 10,000+ artyku≈Ç√≥w
  - ‚úì **Walidacja**: Artyku≈Çy z 2020-2022 w bazie

### Brama jako≈õci
5000+ historycznych artyku≈Ç√≥w z cytowaniami? ‚Üí ‚úÖ Faza 1 uko≈Ñczona!

---

## 1.6 Kontrole jako≈õci danych [2h]

### Zadania
- [ ] **1.6.1** Weryfikuj kompletno≈õƒá danych (30 min)
  - Sprawd≈∫ warto≈õci null
  - Waliduj zakresy dat
  - ‚úì **Walidacja**: <5% brakujƒÖcych danych

- [ ] **1.6.2** Sprawd≈∫ rozk≈Çad sygna≈Ç√≥w (30 min)
  - Wykres rozk≈Çadu wynik√≥w
  - Zakres h-index autor√≥w
  - ‚úì **Walidacja**: Rozk≈Çad normalny

- [ ] **1.6.3** Eksport do trenowania ML (1h)
  - Eksportuj dane historyczne do CSV
  - W≈ÇƒÖcz wszystkie cechy
  - ‚úì **Walidacja**: Czysty plik CSV

---

## Przewodnik rozwiƒÖzywania problem√≥w

### Czƒôste problemy
1. **Limit ArXiv**: Dodaj 3-sekundowe op√≥≈∫nienie miƒôdzy ≈ºƒÖdaniami
2. **Semantic Scholar 404**: Niekt√≥re artyku≈Çy nie zindeksowane, pomi≈Ñ
3. **Limit GitHub**: U≈ºyj uwierzytelnionych ≈ºƒÖda≈Ñ
4. **Timeout Make.com**: Przetwarzaj mniejsze partie

### Wskaz√≥wki optymalizacji
- Cachuj wyszukiwania autor√≥w (ten sam autor wiele artyku≈Ç√≥w)
- Przetwarzaj partiami wed≈Çug zakres√≥w dat
- U≈ºyj data stores Make.com do deduplikacji

---

## Lista kontrolna uko≈Ñczenia fazy
- [ ] Dzienny crawler operacyjny
- [ ] 1000+ ostatnich artyku≈Ç√≥w zebranych
- [ ] 5000+ historycznych artyku≈Ç√≥w z cytowaniami
- [ ] Punktacja wczesnych sygna≈Ç√≥w dzia≈Ça
- [ ] Dane wyeksportowane do trenowania ML

## OsiƒÖgniƒôte metryki
- Zebrane artyku≈Çy: _____
- ≈öredni wynik: _____
- Artyku≈Çy o wysokim wyniku (>60): _____
- Artyku≈Çy historyczne: _____

## Nastƒôpna faza
[‚Üí Faza 2: Rozw√≥j modelu ML](./phase_2_ml_development.md)

---

**≈öledzenie czasu**
- Szacowany: 40h
- Faktyczny: ___h
- Blokery: ___________