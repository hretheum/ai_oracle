# ü§ñ FAZA 2: Rozw√≥j modelu ML

[‚Üê Powr√≥t do g≈Ç√≥wnego planu](./ROADMAP_MASTER.md) | [‚Üê Poprzednia: Faza 1](./phase_1_data_collection.md)

## PrzeglƒÖd
Budowa i deployment modelu ML do przewidywania cytowa≈Ñ. Od prostego modelu do produkcyjnego API.

## Czas trwania i zasoby
- **Ca≈Çkowity czas**: 1 tydzie≈Ñ (40h pracy)
- **Wymagane umiejƒôtno≈õci**: Python, podstawowe ML, rozw√≥j API
- **Bud≈ºet**: $20-50/miesiƒÖc (hosting)

## Kryteria sukcesu
- [ ] Dok≈Çadno≈õƒá modelu >60% na zbiorze testowym
- [ ] API wdro≈ºone i odpowiadajƒÖce
- [ ] Pierwsze 10 predykcji wygenerowanych
- [ ] Integracja z Make.com dzia≈Ça

---

## 2.1 Blok przygotowania danych [8h]

### Wymagania wstƒôpne
- Dane historyczne wyeksportowane z Fazy 1
- ≈örodowisko Python gotowe

### Zadania
- [ ] **2.1.1** Za≈Çaduj i eksploruj dane (1h)
  ```python
  import pandas as pd
  import numpy as np
  import matplotlib.pyplot as plt
  
  # Za≈Çaduj dane
  df = pd.read_csv('oracle_historical_papers.csv')
  print(f"≈ÅƒÖcznie artyku≈Ç√≥w: {len(df)}")
  print(f"Zakres dat: {df['submitted_date'].min()} do {df['submitted_date'].max()}")
  print(f"Zakres cytowa≈Ñ: {df['citations_current'].min()} do {df['citations_current'].max()}")
  
  # Podstawowe statystyki
  df.describe()
  ```
  - ‚úì **Walidacja**: Dane za≈Çadowane, brak b≈Çƒôd√≥w

- [ ] **2.1.2** Oczy≈õƒá dane (1h)
  ```python
  # Usu≈Ñ artyku≈Çy zbyt ≈õwie≈ºe (< 2 lat)
  df['years_old'] = (pd.Timestamp.now() - pd.to_datetime(df['submitted_date'])).dt.days / 365
  df_clean = df[df['years_old'] >= 2].copy()
  
  # Usu≈Ñ warto≈õci odstajƒÖce (artyku≈Çy z 1000+ cytowa≈Ñ)
  df_clean = df_clean[df_clean['citations_current'] < 1000]
  
  # Obs≈Çu≈º brakujƒÖce warto≈õci
  df_clean['author_h_index'].fillna(0, inplace=True)
  df_clean['github_repos'].fillna(0, inplace=True)
  ```
  - ‚úì **Walidacja**: Brak warto≈õci null, rozsƒÖdne zakresy

- [ ] **2.1.3** In≈ºynieria cech (2h)
  ```python
  # Utw√≥rz cechy
  df_clean['has_code'] = df_clean['abstract'].str.contains('github.com|code available', case=False).astype(int)
  df_clean['claims_sota'] = df_clean['abstract'].str.contains('state-of-the-art|sota|outperform', case=False).astype(int)
  df_clean['title_length'] = df_clean['title'].str.split().str.len()
  df_clean['abstract_length'] = df_clean['abstract'].str.split().str.len()
  df_clean['author_count'] = df_clean['authors'].str.count(',') + 1
  
  # Cechy binarne dla top instytucji
  top_institutions = ['MIT', 'Stanford', 'CMU', 'Berkeley', 'Google', 'DeepMind']
  df_clean['has_top_institution'] = df_clean['authors'].apply(
      lambda x: any(inst in str(x) for inst in top_institutions)
  ).astype(int)
  ```
  - ‚úì **Walidacja**: Nowe cechy utworzone

- [ ] **2.1.4** Utw√≥rz zmiennƒÖ docelowƒÖ (1h)
  ```python
  # Normalizuj cytowania wed≈Çug wieku
  df_clean['citations_per_year'] = df_clean['citations_current'] / df_clean['years_old']
  
  # Dla predykcji 3-letniej (nasz g≈Ç√≥wny cel)
  df_clean['citations_3yr_estimated'] = df_clean['citations_per_year'] * 3
  
  # Transformacja logarytmiczna dla lepszego rozk≈Çadu
  df_clean['citations_3yr_log'] = np.log1p(df_clean['citations_3yr_estimated'])
  ```
  - ‚úì **Walidacja**: Zmienna docelowa roz≈Ço≈ºona normalnie

### Brama jako≈õci
Czysty zbi√≥r danych z 3000+ artyku≈Çami i cechami? ‚Üí ‚úÖ Kontynuuj

---

## 2.2 Blok trenowania modelu [8h]

### Zadania
- [ ] **2.2.1** Przygotuj dane treningowe (1h)
  ```python
  # Wybierz cechy
  feature_cols = [
      'author_h_index', 'has_top_institution', 'author_count',
      'has_code', 'claims_sota', 'title_length', 'abstract_length',
      'github_repos', 'early_signals_score'
  ]
  
  X = df_clean[feature_cols]
  y = df_clean['citations_3yr_estimated']
  
  # Podziel dane
  from sklearn.model_selection import train_test_split
  X_train, X_test, y_train, y_test = train_test_split(
      X, y, test_size=0.2, random_state=42
  )
  ```
  - ‚úì **Walidacja**: Podzia≈Ç treningowy/testowy utworzony

- [ ] **2.2.2** Trenuj modele bazowe (2h)
  ```python
  from sklearn.linear_model import LinearRegression, Ridge
  from sklearn.ensemble import RandomForestRegressor
  from sklearn.metrics import mean_absolute_error, r2_score
  
  models = {
      'linear': LinearRegression(),
      'ridge': Ridge(alpha=1.0),
      'rf': RandomForestRegressor(n_estimators=100, random_state=42)
  }
  
  results = {}
  for name, model in models.items():
      model.fit(X_train, y_train)
      y_pred = model.predict(X_test)
      
      mae = mean_absolute_error(y_test, y_pred)
      r2 = r2_score(y_test, y_pred)
      accuracy_20pct = np.mean(np.abs(y_pred - y_test) / y_test < 0.2)
      
      results[name] = {
          'mae': mae,
          'r2': r2,
          'accuracy_20pct': accuracy_20pct
      }
      print(f"{name}: MAE={mae:.2f}, R¬≤={r2:.3f}, Dok≈Çadno≈õƒá 20%={accuracy_20pct:.2%}")
  ```
  - ‚úì **Walidacja**: Przynajmniej jeden model >60% dok≈Çadno≈õci

- [ ] **2.2.3** Optymalizuj najlepszy model (2h)
  ```python
  # Zak≈ÇadajƒÖc, ≈ºe RF dzia≈Ça≈Ç najlepiej
  from sklearn.model_selection import GridSearchCV
  
  param_grid = {
      'n_estimators': [100, 200],
      'max_depth': [10, 20, None],
      'min_samples_split': [2, 5, 10]
  }
  
  grid_search = GridSearchCV(
      RandomForestRegressor(random_state=42),
      param_grid,
      cv=5,
      scoring='neg_mean_absolute_error'
  )
  
  grid_search.fit(X_train, y_train)
  best_model = grid_search.best_estimator_
  ```
  - ‚úì **Walidacja**: Poprawiona dok≈Çadno≈õƒá

- [ ] **2.2.4** Analiza wa≈ºno≈õci cech (1h)
  ```python
  importances = pd.DataFrame({
      'feature': feature_cols,
      'importance': best_model.feature_importances_
  }).sort_values('importance', ascending=False)
  
  print("Najwa≈ºniejsze cechy:")
  print(importances)
  
  # Wizualizuj
  importances.plot(kind='barh', x='feature', y='importance')
  plt.title('Wa≈ºno≈õƒá cech dla predykcji cytowa≈Ñ')
  plt.tight_layout()
  plt.savefig('feature_importance.png')
  ```
  - ‚úì **Walidacja**: h-index autora w top 3 cechach

### Brama jako≈õci
Dok≈Çadno≈õƒá modelu >60% w marginesie 20%? ‚Üí ‚úÖ Kontynuuj

---

## 2.3 Blok wdro≈ºenia modelu [8h]

### Zadania
- [ ] **2.3.1** Zapisz model (30 min)
  ```python
  import joblib
  
  # Zapisz model i metadane
  model_data = {
      'model': best_model,
      'features': feature_cols,
      'version': '1.0',
      'training_date': pd.Timestamp.now().isoformat(),
      'metrics': results
  }
  
  joblib.dump(model_data, 'oracle_model_v1.pkl')
  ```
  - ‚úì **Walidacja**: Plik utworzony

- [ ] **2.3.2** Utw√≥rz Flask API (2h)
  ```python
  # app.py
  from flask import Flask, request, jsonify
  import joblib
  import pandas as pd
  import numpy as np
  
  app = Flask(__name__)
  
  # Za≈Çaduj model
  model_data = joblib.load('oracle_model_v1.pkl')
  model = model_data['model']
  features = model_data['features']
  
  @app.route('/predict', methods=['POST'])
  def predict():
      try:
          # Pobierz cechy z ≈ºƒÖdania
          data = request.json
          
          # Utw√≥rz dataframe
          df = pd.DataFrame([data['features']])
          
          # Zapewnij obecno≈õƒá wszystkich cech
          for feat in features:
              if feat not in df.columns:
                  df[feat] = 0
          
          # Przewiduj
          prediction = model.predict(df[features])[0]
          
          # Oblicz pewno≈õƒá (prosta wersja)
          confidence = min(0.85, max(0.5, 0.6 + (prediction / 1000)))
          
          # Oszacuj percentyl
          if prediction < 10:
              percentile = 50
          elif prediction < 50:
              percentile = 75
          elif prediction < 200:
              percentile = 90
          else:
              percentile = 95
          
          return jsonify({
              'success': True,
              'predictions': {
                  'citations_1yr': int(prediction * 0.3),
                  'citations_3yr': int(prediction),
                  'citations_5yr': int(prediction * 1.8)
              },
              'confidence': round(confidence, 2),
              'percentile': percentile,
              'model_version': model_data['version']
          })
          
      except Exception as e:
          return jsonify({
              'success': False,
              'error': str(e)
          }), 400
  
  @app.route('/health', methods=['GET'])
  def health():
      return jsonify({'status': 'healthy', 'model_version': model_data['version']})
  
  if __name__ == '__main__':
      app.run(debug=True, port=5000)
  ```
  - ‚úì **Walidacja**: API odpowiada lokalnie

- [ ] **2.3.3** Testuj API lokalnie (1h)
  ```bash
  # Uruchom serwer
  python app.py
  
  # Testuj predykcjƒô
  curl -X POST http://localhost:5000/predict \
    -H "Content-Type: application/json" \
    -d '{
      "features": {
        "author_h_index": 25,
        "has_top_institution": 1,
        "author_count": 3,
        "has_code": 1,
        "claims_sota": 1,
        "title_length": 12,
        "abstract_length": 250,
        "github_repos": 2,
        "early_signals_score": 75
      }
    }'
  ```
  - ‚úì **Walidacja**: Zwraca JSON z predykcjƒÖ

- [ ] **2.3.4** Wdr√≥≈º na Railway (2h)
  - Utw√≥rz requirements.txt
  - Dodaj Procfile: `web: gunicorn app:app`
  - Wypchnij do GitHub
  - Po≈ÇƒÖcz Railway z repo
  - Wdr√≥≈º
  - ‚úì **Walidacja**: Publiczny URL dzia≈Ça

### Brama jako≈õci
API wdro≈ºone i odpowiadajƒÖce? ‚Üí ‚úÖ Kontynuuj

---

## 2.4 Blok integracji Make.com [4h]

### Zadania
- [ ] **2.4.1** Utw√≥rz scenariusz predykcji (1h)
  - Nowy scenariusz: "Oracle - ML Predictions"
  - Wyzwalacz: Codziennie o 10:00 UTC
  - ‚úì **Walidacja**: Scenariusz utworzony

- [ ] **2.4.2** Pobierz artyku≈Çy o wysokim wyniku (30 min)
  - Modu≈Ç wyszukiwania Airtable
  - Filtr: `AND({needs_prediction}, NOT({predicted}))`
  - Limit: 10
  - ‚úì **Walidacja**: Zwraca artyku≈Çy

- [ ] **2.4.3** Wywo≈Çaj API predykcji (1h)
  ```
  Modu≈Ç HTTP Request:
  - URL: https://your-api.railway.app/predict
  - Metoda: POST
  - Nag≈Ç√≥wki: Content-Type: application/json
  - Tre≈õƒá: {
      "features": {
        "author_h_index": {{item.author_h_index}},
        "has_top_institution": {{if(item.has_top_institution; 1; 0)}},
        ...
      }
    }
  ```
  - ‚úì **Walidacja**: Zwraca predykcje

- [ ] **2.4.4** Aktualizuj Airtable (30 min)
  - Aktualizuj rekord z predykcjami
  - Ustaw predicted = true
  - Dodaj prediction_date
  - ‚úì **Walidacja**: Rekordy zaktualizowane

### Brama jako≈õci
10 artyku≈Ç√≥w przewidzianych przez automatyzacjƒô? ‚Üí ‚úÖ Faza 2 uko≈Ñczona!

---

## 2.5 Kontrola jako≈õci pierwszych predykcji [4h]

### Zadania
- [ ] **2.5.1** PrzeglƒÖd rƒôczny (1h)
  - Sprawd≈∫ 10 predykcji
  - Czy majƒÖ intuicyjny sens?
  - ‚úì **Walidacja**: Brak oczywistych b≈Çƒôd√≥w

- [ ] **2.5.2** Utw√≥rz tre≈õƒá predykcyjnƒÖ (2h)
  - Dla top 5 predykcji
  - Napisz wyja≈õnienia
  - Utw√≥rz wizualizacje
  - ‚úì **Walidacja**: Tre≈õƒá gotowa

- [ ] **2.5.3** Udokumentuj metodologiƒô (1h)
  - Jakie cechy u≈ºywamy
  - Jak trenujemy model
  - Aktualne metryki dok≈Çadno≈õci
  - ‚úì **Walidacja**: Opublikowane na stronie

---

## Lista kontrolna uko≈Ñczenia fazy
- [ ] Model wytrenowany z >60% dok≈Çadno≈õciƒÖ
- [ ] API wdro≈ºone i stabilne
- [ ] Integracja Make.com dzia≈Ça
- [ ] Pierwsze 10+ predykcji wykonanych
- [ ] Metodologia udokumentowana

## OsiƒÖgniƒôte metryki
- Dok≈Çadno≈õƒá modelu (margines 20%): ____%
- Czas odpowiedzi API: ____ms
- Wykonane predykcje: ____
- Predykcje o wysokiej pewno≈õci: ____

## Nastƒôpna faza
[‚Üí Faza 3: Uruchomienie MVP](./phase_3_mvp_launch.md)

---

**≈öledzenie czasu**
- Szacowany: 40h
- Faktyczny: ___h
- Blokery: ___________